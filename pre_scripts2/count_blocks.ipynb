{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def merge_intervals(intervals):\n",
    "    \"\"\"\n",
    "    Given a list of (start, end) intervals (assumed sorted by start),\n",
    "    merge overlapping intervals and return the merged list.\n",
    "    \"\"\"\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals = sorted(intervals, key=lambda x: x[0])\n",
    "    merged = [intervals[0]]\n",
    "    for current in intervals[1:]:\n",
    "        prev_start, prev_end = merged[-1]\n",
    "        cur_start, cur_end = current\n",
    "        if cur_start <= prev_end:  # Overlap\n",
    "            merged[-1] = (prev_start, max(prev_end, cur_end))\n",
    "        else:\n",
    "            merged.append(current)\n",
    "    return merged\n",
    "\n",
    "def max_aircraft_count(df, trenches, lat_min, lat_max, lon_min, lon_max, cell_size, window_size):\n",
    "    lat_bounds = np.arange(lat_min, lat_max + cell_size, cell_size)\n",
    "    lon_bounds = np.arange(lon_min, lon_max + cell_size, cell_size)\n",
    "    \n",
    "    # Dictionary to accumulate time intervals.\n",
    "    # Key: (window_start, alt_trench_idx, lat_idx, lon_idx)\n",
    "    # Value: dict mapping flight id -> list of (t_start, t_end) intervals (seconds)\n",
    "    intervals_dict = {}\n",
    "    \n",
    "    # Process each flight segment\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Counting aircraft\"):\n",
    "        flight_id = row['id']\n",
    "        seg_start = float(row['from_time'])\n",
    "        seg_end   = float(row['to_time'])\n",
    "        seg_duration = seg_end - seg_start\n",
    "        if seg_duration <= 0:\n",
    "            continue\n",
    "        \n",
    "        lat0, lat1 = float(row['from_lat']), float(row['to_lat'])\n",
    "        lon0, lon1 = float(row['from_lon']), float(row['to_lon'])\n",
    "        alt0, alt1 = float(row['from_alt']), float(row['to_alt'])\n",
    "        \n",
    "        # Determine overlapping 15â€‘minute windows.\n",
    "        window_start = floor(seg_start / window_size) * window_size\n",
    "        while window_start < seg_end:\n",
    "            window_end = window_start + window_size\n",
    "            t0 = max(seg_start, window_start)\n",
    "            t1 = min(seg_end, window_end)\n",
    "            if t1 <= t0:\n",
    "                window_start += window_size\n",
    "                continue\n",
    "            \n",
    "            tau0 = (t0 - seg_start) / seg_duration\n",
    "            tau1 = (t1 - seg_start) / seg_duration\n",
    "            taus = [tau0, tau1]\n",
    "            \n",
    "            # Helper to add a tau value within (tau0, tau1)\n",
    "            def add_tau(t):\n",
    "                if tau0 < t < tau1:\n",
    "                    taus.append(t)\n",
    "            \n",
    "            # Latitude grid boundaries\n",
    "            if lat1 != lat0:\n",
    "                lat_seg_min, lat_seg_max = min(lat0, lat1), max(lat0, lat1)\n",
    "                for b in lat_bounds:\n",
    "                    if lat_seg_min < b < lat_seg_max:\n",
    "                        t_val = (b - lat0) / (lat1 - lat0)\n",
    "                        add_tau(t_val)\n",
    "            \n",
    "            # Longitude grid boundaries\n",
    "            if lon1 != lon0:\n",
    "                lon_seg_min, lon_seg_max = min(lon0, lon1), max(lon0, lon1)\n",
    "                for b in lon_bounds:\n",
    "                    if lon_seg_min < b < lon_seg_max:\n",
    "                        t_val = (b - lon0) / (lon1 - lon0)\n",
    "                        add_tau(t_val)\n",
    "            \n",
    "            # Altitude trench boundaries\n",
    "            if alt1 != alt0:\n",
    "                for alt_lower, alt_upper in trenches:\n",
    "                    # Check lower boundary\n",
    "                    if (alt_lower - alt0) * (alt_lower - alt1) < 0:\n",
    "                        t_val = (alt_lower - alt0) / (alt1 - alt0)\n",
    "                        add_tau(t_val)\n",
    "                    # Check upper boundary\n",
    "                    if (alt_upper - alt0) * (alt_upper - alt1) < 0:\n",
    "                        t_val = (alt_upper - alt0) / (alt1 - alt0)\n",
    "                        add_tau(t_val)\n",
    "            \n",
    "            taus = sorted(set(taus))\n",
    "            \n",
    "            # Break the segment in this window into subintervals\n",
    "            for i in range(len(taus) - 1):\n",
    "                tau_sub0, tau_sub1 = taus[i], taus[i+1]\n",
    "                tau_mid = (tau_sub0 + tau_sub1) / 2.0\n",
    "                \n",
    "                # Compute mid-point of the subinterval\n",
    "                lat_mid = lat0 + tau_mid * (lat1 - lat0)\n",
    "                lon_mid = lon0 + tau_mid * (lon1 - lon0)\n",
    "                alt_mid = alt0 + tau_mid * (alt1 - alt0)\n",
    "                \n",
    "                if not (lat_min <= lat_mid <= lat_max and lon_min <= lon_mid <= lon_max):\n",
    "                    continue\n",
    "                \n",
    "                # Determine grid cell indices\n",
    "                lat_idx = int((lat_mid - lat_min) / cell_size)\n",
    "                lon_idx = int((lon_mid - lon_min) / cell_size)\n",
    "                \n",
    "                # Determine altitude trench index\n",
    "                alt_trench_idx = None\n",
    "                for idx_trench, (alt_low, alt_high) in enumerate(trenches):\n",
    "                    if alt_low <= alt_mid < alt_high:\n",
    "                        alt_trench_idx = idx_trench\n",
    "                        break\n",
    "                if alt_trench_idx is None:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate the absolute start and end times for this subinterval\n",
    "                t_sub_start = seg_start + tau_sub0 * seg_duration\n",
    "                t_sub_end   = seg_start + tau_sub1 * seg_duration\n",
    "                \n",
    "                key = (window_start, alt_trench_idx, lat_idx, lon_idx)\n",
    "                if key not in intervals_dict:\n",
    "                    intervals_dict[key] = {}\n",
    "                if flight_id not in intervals_dict[key]:\n",
    "                    intervals_dict[key][flight_id] = []\n",
    "                intervals_dict[key][flight_id].append((t_sub_start, t_sub_end))\n",
    "            \n",
    "            window_start += window_size\n",
    "    \n",
    "    # Now, for each grid cell in each window, compute the maximum instantaneous\n",
    "    # count (i.e. the maximum number of flights concurrently present).\n",
    "    results = {}\n",
    "    for key, flights in intervals_dict.items():\n",
    "        # We'll collect events from all flight intervals.\n",
    "        events = []\n",
    "        # For each flight, merge intervals (so overlapping intervals for the same flight\n",
    "        # are counted only once) and add start/end events.\n",
    "        for flight_id, interval_list in flights.items():\n",
    "            merged = merge_intervals(interval_list)\n",
    "            for start, end in merged:\n",
    "                # Use (time, delta) events. To ensure that an interval ending at the same\n",
    "                # time another begins does not count as overlap, we sort end events before start events.\n",
    "                events.append((start, 1))\n",
    "                events.append((end, -1))\n",
    "        if not events:\n",
    "            results[key] = 0\n",
    "            continue\n",
    "        # Sort events by time; in case of ties, end (-1) events come before start (+1)\n",
    "        events.sort(key=lambda x: (x[0], x[1]))\n",
    "        \n",
    "        current_count = 0\n",
    "        max_count = 0\n",
    "        for time, delta in events:\n",
    "            current_count += delta\n",
    "            max_count = max(max_count, current_count)\n",
    "        results[key] = max_count\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Program Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "def process_file(file_path, trenches, lat_min, lat_max, lon_min, lon_max, cell_size, window_size):\n",
    "    \"\"\"\n",
    "    Process a single CSV file and save the results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Apply the max_aircraft_count function\n",
    "        results = max_aircraft_count(df, trenches, lat_min, lat_max, lon_min, lon_max, cell_size, window_size)\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame([\n",
    "            {\n",
    "                'window_start': key[0],\n",
    "                'alt_trench_idx': key[1],\n",
    "                'lat_idx': key[2],\n",
    "                'lon_idx': key[3],\n",
    "                'max_count': count\n",
    "            }\n",
    "            for key, count in results.items()\n",
    "        ])\n",
    "        \n",
    "        # Create the output path\n",
    "        output_path = file_path.replace('routes', 'counts')\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Save the results\n",
    "        results_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        return file_path, True\n",
    "    except Exception as e:\n",
    "        return file_path, f\"Error: {str(e)}\"\n",
    "\n",
    "def process_all_files(routes_dir='routes', num_processes=None, \n",
    "                     trenches=[(0, 10000), (10000, 20000), (20000, 40000)],\n",
    "                     lat_min=45.0, lat_max=55.0, lon_min=20.0, lon_max=40.0,\n",
    "                     cell_size=0.1, window_size=900):  # window_size=900 for 15 minutes in seconds\n",
    "    \"\"\"\n",
    "    Process all CSV files in the routes directory and its subdirectories.\n",
    "    \n",
    "    Parameters:\n",
    "    - routes_dir: Directory containing the route files\n",
    "    - num_processes: Number of processes to use (defaults to CPU count)\n",
    "    - trenches, lat_min, lat_max, lon_min, lon_max, cell_size, window_size: Parameters for max_aircraft_count\n",
    "    \"\"\"\n",
    "    # Find all CSV files in the routes directory and its subdirectories\n",
    "    csv_files = glob.glob(os.path.join(routes_dir, '**', '*.csv'), recursive=True)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {routes_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} CSV files to process\")\n",
    "    \n",
    "    # Create the counts directory if it doesn't exist\n",
    "    counts_dir = 'counts'\n",
    "    os.makedirs(counts_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a partial function with fixed parameters\n",
    "    process_func = partial(\n",
    "        process_file,\n",
    "        trenches=trenches,\n",
    "        lat_min=lat_min,\n",
    "        lat_max=lat_max,\n",
    "        lon_min=lon_min,\n",
    "        lon_max=lon_max,\n",
    "        cell_size=cell_size,\n",
    "        window_size=window_size\n",
    "    )\n",
    "    \n",
    "    # Process files in parallel\n",
    "    start_time = time.time()\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        results = list(tqdm(\n",
    "            pool.imap(process_func, csv_files),\n",
    "            total=len(csv_files),\n",
    "            desc=\"Processing files\"\n",
    "        ))\n",
    "    \n",
    "    # Report results\n",
    "    success_count = sum(1 for _, status in results if status is True)\n",
    "    failed_files = [(file, status) for file, status in results if status is not True]\n",
    "    \n",
    "    print(f\"Processing completed in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"Successfully processed {success_count} out of {len(csv_files)} files\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(f\"Failed to process {len(failed_files)} files:\")\n",
    "        for file, error in failed_files[:10]:  # Show first 10 errors\n",
    "            print(f\"  - {file}: {error}\")\n",
    "        if len(failed_files) > 10:\n",
    "            print(f\"  ... and {len(failed_files) - 10} more\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define your parameters here\n",
    "    altitude_trenches = [\n",
    "        (7315.2, 8839.2),  # Lower En-Route (24,000 ft to 29,000 ft in meters)\n",
    "        (8839.2, 10668.0),  # Upper En-Route, Lower RVSM (29,000 ft to 35,000 ft in meters)\n",
    "        (10668.0, 21243.0)  # Upper En-Route, Upper RVSM (35,000 ft to 69,696 ft in meters)\n",
    "    ]\n",
    "    \n",
    "    lat_min, lat_max = 30.0, 72.0  # Example latitude range\n",
    "    lon_min, lon_max = -15.0, 40.0  # Example longitude range\n",
    "    cell_size = 0.25  # Example cell size in degrees\n",
    "    window_size = 15 * 60  # 15 minutes in seconds\n",
    "    \n",
    "    process_all_files(\n",
    "        routes_dir='routes',\n",
    "        num_processes=None,\n",
    "        trenches=altitude_trenches,\n",
    "        lat_min=lat_min,\n",
    "        lat_max=lat_max,\n",
    "        lon_min=lon_min,\n",
    "        lon_max=lon_max,\n",
    "        cell_size=cell_size,\n",
    "        window_size=window_size\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukraine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
